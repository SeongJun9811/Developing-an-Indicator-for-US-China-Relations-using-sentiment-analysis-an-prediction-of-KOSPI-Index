# -*- coding: utf-8 -*-
"""KR-FinBert-SC 감성분석.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19OSyWaxL3qSVwpY2fHVNRIYs4JCtm7XM
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd

# 파일이 저장된 디렉토리 경로
directory_path = '/content/drive/MyDrive/Colab Notebooks/news_data/'

# 모든 파일의 데이터를 저장할 빈 데이터프레임 생성
all_data = pd.DataFrame()

# 디렉토리 내의 모든 Excel 파일을 반복하여 처리
for filename in os.listdir(directory_path):
    if filename.endswith('.xlsx'):
        file_path = os.path.join(directory_path, filename)

        # Excel 파일을 데이터프레임으로 읽어오기
        data = pd.read_excel(file_path)

        # 현재 파일의 데이터를 기존 데이터프레임에 이어붙이기
        all_data = pd.concat([all_data, data], ignore_index=True)

word_data = all_data[['date','title','contents']]

import re

def text_cleaning(text):
    if pd.isnull(text):
        return ""  # NaN이면 빈 문자열로 처리
    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')    # ㅣ : 한글 ㅣ (이)
    result = hangul.sub('',text)
    return result

word_data['title'] = word_data['title'].apply(lambda x: text_cleaning(x))
word_data['contents'] = word_data['contents'].apply(lambda x: text_cleaning(x))

word_data['all'] = word_data['title'] + ' ' + word_data['contents']
word_data

#추론 모델 인스턴스 생성 및 테스트
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import pipeline
tokenizer=AutoTokenizer.from_pretrained('snunlp/KR-FinBert-SC')
model=AutoModelForSequenceClassification.from_pretrained('snunlp/KR-FinBert-SC')
senti_classifier=pipeline(task='text-classification',model=model,tokenizer=tokenizer)

data_all=word_data['all']
data_all

import pandas as pd

# 빈 DataFrame 생성
df = pd.DataFrame(columns=['text', 'senti'])

for i in range(0, len(data_all)):
    x = data_all[i]
    y = [x['label'] for x in senti_classifier(x)]
    df_next = pd.DataFrame(data={
        'text': x,
        'senti': y
    })
    df = pd.concat([df, df_next])

# 결과 확인
print(df)

df.to_csv('FInBert_US_C.csv', index=False)

df2 = pd.read_csv('/content/FInBert_US_C.csv')

df2['date'] = word_data['date']

df2 = df2[df2['senti'] != 'neutral']

df2

# 'date' 열을 날짜형으로 변환
df2['date'] = pd.to_datetime(df2['date'])

# 'date' 열을 기준으로 월별로 그룹화하고 'senti' 열의 positive와 negative의 개수를 계산
monthly_sentiment_counts = df2.groupby(df2['date'].dt.to_period("M"))['senti'].value_counts().unstack(fill_value=0)

monthly_sentiment_counts['score'] = (monthly_sentiment_counts['positive'] - monthly_sentiment_counts['negative'])/100
monthly_sentiment_counts

monthly_sentiment_counts.to_csv('US_C_indi_FInBert.csv', index=False)

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
monthly_sentiment_counts['score'].plot(kind='line', marker='o')
plt.title('US-China relation indicator')
plt.xlabel('Date')
plt.ylabel('indicator')
plt.grid(True)
plt.savefig('KR_FinBert기반_지표.jpg', dpi=1500, bbox_inches='tight')